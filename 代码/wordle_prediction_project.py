"""
Wordleç©å®¶è¡¨ç°é¢„æµ‹é¡¹ç›® - å®Œæ•´ä»£ç 
åŒ…å«æ•°æ®å¤„ç†ã€æ¨¡å‹æ„å»ºã€è®­ç»ƒã€è¯„ä¼°å…¨æµç¨‹
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, roc_curve, auc
import tensorflow as tf
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Attention, Dropout, GlobalAveragePooling1D
from tensorflow.keras.layers import TransformerEncoder, TransformerEncoderLayer
from tensorflow.keras.callbacks import EarlyStopping
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei']
plt.rcParams['axes.unicode_minus'] = False


# ==============================================================================
# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
# ==============================================================================
def load_and_preprocess_data(file_path):
    """åŠ è½½å¹¶é¢„å¤„ç†Wordleæ•°æ®"""
    # è¯»å–æ•°æ®
    df = pd.read_excel(file_path, header=1)

    # è®¾ç½®åˆ—å
    new_columns = [
        'delete_col', 'Date', 'Contest_number', 'Word',
        'Reported_results', 'Hard_mode_count',
        '1_try_pct', '2_tries_pct', '3_tries_pct',
        '4_tries_pct', '5_tries_pct', '6_tries_pct',
        '7_plus_tries_pct'
    ]
    df.columns = new_columns

    # æ•°æ®æ¸…æ´—
    df = df.drop('delete_col', axis=1)
    df = df.dropna()

    # æ•°æ®ç±»å‹è½¬æ¢
    df['Date'] = pd.to_datetime(df['Date'])
    numeric_cols = ['Contest_number', 'Reported_results', 'Hard_mode_count'] + \
                   [f'{i}_tries_pct' for i in range(1, 7)] + ['7_plus_tries_pct']

    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df = df.dropna()
    df = df.sort_values('Date').reset_index(drop=True)

    # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
    tries_weights = np.array([1, 2, 3, 4, 5, 6, 7])
    tries_matrix = df[[f'{i}_tries_pct' for i in range(1, 7)] + ['7_plus_tries_pct']].values / 100

    df['Average_tries'] = np.dot(tries_matrix, tries_weights)
    df['Success_rate'] = (df['1_try_pct'] + df['2_tries_pct'] + df['3_tries_pct'] +
                          df['4_tries_pct'] + df['5_tries_pct'] + df['6_tries_pct']) / 100
    df['Hard_mode_ratio'] = df['Hard_mode_count'] / df['Reported_results']
    df['Tries_std'] = np.sqrt(
        np.sum(tries_matrix * (tries_weights - df['Average_tries'].values.reshape(-1, 1)) ** 2, axis=1))
    df['high_success'] = (df['Success_rate'] > df['Success_rate'].mean()).astype(int)

    return df


# ==============================================================================
# 2. ç‰¹å¾å·¥ç¨‹ - æ—¶é—´åºåˆ—æ•°æ®å‡†å¤‡
# ==============================================================================
class WordleFeatureEngineering:
    def __init__(self, df, sequence_length=7):
        self.df = df.copy()
        self.sequence_length = sequence_length
        self.scalers = {}

    def normalize_features(self, feature_columns):
        """æ ‡å‡†åŒ–ç‰¹å¾"""
        for col in feature_columns:
            scaler = StandardScaler()
            self.df[f'norm_{col}'] = scaler.fit_transform(self.df[[col]])
            self.scalers[col] = scaler
        return self.df

    def create_time_sequences(self, target_column, feature_columns):
        """åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®"""
        X, y = [], []
        norm_feature_cols = [f'norm_{col}' for col in feature_columns]
        feature_data = self.df[norm_feature_cols].values
        target_data = self.df[target_column].values

        for i in range(len(self.df) - self.sequence_length):
            seq_features = feature_data[i:i + self.sequence_length]
            seq_target = target_data[i + self.sequence_length]
            X.append(seq_features)
            y.append(seq_target)

        return np.array(X), np.array(y)


# ==============================================================================
# 3. æ¨¡å‹æ„å»º - LSTMç³»åˆ—æ¨¡å‹
# ==============================================================================
class WordleLSTMModels:
    def __init__(self, input_shape):
        self.input_shape = input_shape

    def build_basic_lstm_regressor(self):
        """åŸºç¡€LSTMå›å½’æ¨¡å‹ï¼ˆé¢„æµ‹å¹³å‡å°è¯•æ¬¡æ•°ï¼‰"""
        inputs = Input(shape=self.input_shape)
        lstm1 = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inputs)
        lstm2 = LSTM(32, dropout=0.2, recurrent_dropout=0.2)(lstm1)
        dense1 = Dense(16, activation='relu')(lstm2)
        dropout1 = Dropout(0.2)(dense1)
        outputs = Dense(1, activation='linear')(dropout1)

        model = Model(inputs=inputs, outputs=outputs)
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model

    def build_basic_lstm_classifier(self):
        """åŸºç¡€LSTMåˆ†ç±»æ¨¡å‹ï¼ˆé¢„æµ‹é«˜æˆåŠŸç‡ï¼‰"""
        inputs = Input(shape=self.input_shape)
        lstm1 = LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inputs)
        lstm2 = LSTM(32, dropout=0.2, recurrent_dropout=0.2)(lstm1)
        dense1 = Dense(16, activation='relu')(lstm2)
        dropout1 = Dropout(0.2)(dense1)
        outputs = Dense(1, activation='sigmoid')(dropout1)

        model = Model(inputs=inputs, outputs=outputs)
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        return model

    def build_bilstm_attention_regressor(self):
        """BiLSTM+Attentionå›å½’æ¨¡å‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        inputs = Input(shape=self.input_shape)
        bilstm = Bidirectional(LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(inputs)
        attention = Attention()([bilstm, bilstm])
        attention_flatten = tf.keras.layers.Flatten()(attention)
        dense1 = Dense(32, activation='relu')(attention_flatten)
        dropout1 = Dropout(0.2)(dense1)
        dense2 = Dense(16, activation='relu')(dropout1)
        outputs = Dense(1, activation='linear')(dense2)

        model = Model(inputs=inputs, outputs=outputs)
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model


# ==============================================================================
# 4. æ¨¡å‹æ„å»º - Transformeræ¨¡å‹ï¼ˆæ‰©å±•ä»»åŠ¡ï¼‰
# ==============================================================================
class WordleTransformerModels:
    def __init__(self, input_shape, d_model=64, nhead=4, num_layers=2):
        self.input_shape = input_shape
        self.d_model = d_model
        self.nhead = nhead
        self.num_layers = num_layers

    def _positional_encoding(self, seq_len, d_model):
        """ç”Ÿæˆä½ç½®ç¼–ç """
        position = np.arange(seq_len)[:, np.newaxis]
        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))

        pos_enc = np.zeros((seq_len, d_model))
        pos_enc[:, 0::2] = np.sin(position * div_term)
        pos_enc[:, 1::2] = np.cos(position * div_term)

        return tf.constant(pos_enc, dtype=tf.float32)[np.newaxis, ...]

    def build_transformer_regressor(self):
        """Transformerå›å½’æ¨¡å‹"""
        inputs = Input(shape=self.input_shape)
        projection = Dense(self.d_model)(inputs)
        seq_len = self.input_shape[0]
        pos_encoding = self._positional_encoding(seq_len, self.d_model)
        x = projection + pos_encoding

        encoder_layer = TransformerEncoderLayer(
            d_model=self.d_model,
            nhead=self.nhead,
            dropout=0.2
        )
        transformer_encoder = TransformerEncoder(encoder_layer, num_layers=self.num_layers)
        x = transformer_encoder(x)

        x = GlobalAveragePooling1D()(x)
        x = Dense(32, activation='relu')(x)
        x = Dropout(0.2)(x)
        x = Dense(16, activation='relu')(x)
        outputs = Dense(1, activation='linear')(x)

        model = Model(inputs=inputs, outputs=outputs)
        model.compile(optimizer='adam', loss='mse', metrics=['mae'])
        return model


# ==============================================================================
# 5. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°å·¥å…·å‡½æ•°
# ==============================================================================
def train_model(model, X_train, y_train, epochs=50, batch_size=8, validation_split=0.2):
    """è®­ç»ƒæ¨¡å‹ï¼ˆå«æ—©åœæœºåˆ¶ï¼‰"""
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

    history = model.fit(
        X_train, y_train,
        validation_split=validation_split,
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[early_stopping],
        verbose=1
    )

    return model, history


def evaluate_regression_model(model, X_test, y_test, model_name):
    """è¯„ä¼°å›å½’æ¨¡å‹"""
    y_pred = model.predict(X_test, verbose=0)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(y_test - y_pred))

    print(f"\n{model_name} å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f" - MSE (å‡æ–¹è¯¯å·®): {mse:.4f}")
    print(f" - RMSE (å‡æ–¹æ ¹è¯¯å·®): {rmse:.4f}")
    print(f" - MAE (å¹³å‡ç»å¯¹è¯¯å·®): {mae:.4f}")

    return y_pred, {'mse': mse, 'rmse': rmse, 'mae': mae}


def evaluate_classification_model(model, X_test, y_test, model_name):
    """è¯„ä¼°åˆ†ç±»æ¨¡å‹"""
    y_pred_prob = model.predict(X_test, verbose=0)
    y_pred = (y_pred_prob > 0.5).astype(int)

    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)

    print(f"\n{model_name} åˆ†ç±»æ¨¡å‹è¯„ä¼°ç»“æœ:")
    print(f" - å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f}")
    print(f" - ç²¾ç¡®ç‡ (Precision): {report['1']['precision']:.4f}")
    print(f" - å¬å›ç‡ (Recall): {report['1']['recall']:.4f}")
    print(f" - F1åˆ†æ•°: {report['1']['f1-score']:.4f}")

    return y_pred, y_pred_prob, {'accuracy': accuracy, 'precision': report['1']['precision'],
                                 'recall': report['1']['recall'], 'f1': report['1']['f1-score']}


# ==============================================================================
# 6. ä¸»å‡½æ•° - é¡¹ç›®æ‰§è¡Œå…¥å£
# ==============================================================================
def main(file_path, sequence_length=7):
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´é¡¹ç›®æµç¨‹"""
    print("=" * 60)
    print("Wordleç©å®¶è¡¨ç°é¢„æµ‹é¡¹ç›® - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)

    # 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
    print("\\n1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†...")
    df = load_and_preprocess_data(file_path)
    print(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {df.shape}")

    # 2. ç‰¹å¾å·¥ç¨‹ä¸æ—¶é—´åºåˆ—å‡†å¤‡
    print("\\n2. ç‰¹å¾å·¥ç¨‹ä¸æ—¶é—´åºåˆ—æ•°æ®å‡†å¤‡...")
    feature_columns = [
        'Average_tries', 'Success_rate', 'Hard_mode_ratio', 'Tries_std',
        '1_try_pct', '2_tries_pct', '3_tries_pct', '4_tries_pct',
        '5_tries_pct', '6_tries_pct', '7_plus_tries_pct',
        'Reported_results', 'Hard_mode_count'
    ]

    # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹
    fe = WordleFeatureEngineering(df, sequence_length=sequence_length)
    df_processed = fe.normalize_features(feature_columns)

    # ç”Ÿæˆå›å½’å’Œåˆ†ç±»ä»»åŠ¡çš„æ—¶é—´åºåˆ—æ•°æ®
    X_reg, y_reg = fe.create_time_sequences('Average_tries', feature_columns)  # å›å½’ï¼šé¢„æµ‹å¹³å‡å°è¯•æ¬¡æ•°
    X_cls, y_cls = fe.create_time_sequences('high_success', feature_columns)  # åˆ†ç±»ï¼šé¢„æµ‹é«˜æˆåŠŸç‡

    # åˆ’åˆ†è®­ç»ƒé›†ï¼ˆ80%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ20%ï¼‰
    split_idx = int(len(X_reg) * 0.8)
    X_reg_train, X_reg_test = X_reg[:split_idx], X_reg[split_idx:]
    y_reg_train, y_reg_test = y_reg[:split_idx], y_reg[split_idx:]
    X_cls_train, X_cls_test = X_cls[:split_idx], X_cls[split_idx:]
    y_cls_train, y_cls_test = y_cls[:split_idx], y_cls[split_idx:]

    print(f"âœ… æ—¶é—´åºåˆ—æ•°æ®å‡†å¤‡å®Œæˆ:")
    print(f"   - å›å½’ä»»åŠ¡: è®­ç»ƒé›†{X_reg_train.shape}, æµ‹è¯•é›†{X_reg_test.shape}")
    print(f"   - åˆ†ç±»ä»»åŠ¡: è®­ç»ƒé›†{X_cls_train.shape}, æµ‹è¯•é›†{X_cls_test.shape}")

    # 3. æ¨¡å‹æ„å»ºä¸è®­ç»ƒ
    input_shape = (X_reg_train.shape[1], X_reg_train.shape[2])  # (sequence_length, num_features)
    print(f"\\n3. æ¨¡å‹æ„å»ºä¸è®­ç»ƒ (è¾“å…¥å½¢çŠ¶: {input_shape})...")

    # 3.1 è®­ç»ƒåŸºç¡€LSTMå›å½’æ¨¡å‹
    print("\\n3.1 è®­ç»ƒåŸºç¡€LSTMå›å½’æ¨¡å‹...")
    lstm_builder = WordleLSTMModels(input_shape)
    lstm_reg_model = lstm_builder.build_basic_lstm_regressor()
    lstm_reg_model, _ = train_model(lstm_reg_model, X_reg_train, y_reg_train)
    lstm_reg_model.save('lstm_regression_model.h5')
    print("âœ… åŸºç¡€LSTMå›å½’æ¨¡å‹å·²ä¿å­˜")

    # 3.2 è®­ç»ƒåŸºç¡€LSTMåˆ†ç±»æ¨¡å‹
    print("\\n3.2 è®­ç»ƒåŸºç¡€LSTMåˆ†ç±»æ¨¡å‹...")
    lstm_cls_model = lstm_builder.build_basic_lstm_classifier()
    lstm_cls_model, _ = train_model(lstm_cls_model, X_cls_train, y_cls_train)
    lstm_cls_model.save('lstm_classification_model.h5')
    print("âœ… åŸºç¡€LSTMåˆ†ç±»æ¨¡å‹å·²ä¿å­˜")

    # 3.3 è®­ç»ƒBiLSTM+Attentionå›å½’æ¨¡å‹
    print("\\n3.3 è®­ç»ƒBiLSTM+Attentionå›å½’æ¨¡å‹...")
    bilstm_att_reg_model = lstm_builder.build_bilstm_attention_regressor()
    bilstm_att_reg_model, _ = train_model(bilstm_att_reg_model, X_reg_train, y_reg_train)
    bilstm_att_reg_model.save('bilstm_attention_regression_model.h5')
    print("âœ… BiLSTM+Attentionå›å½’æ¨¡å‹å·²ä¿å­˜")

    # 3.4 è®­ç»ƒTransformerå›å½’æ¨¡å‹ï¼ˆæ‰©å±•ä»»åŠ¡ï¼‰
    print("\\n3.4 è®­ç»ƒTransformerå›å½’æ¨¡å‹...")
    transformer_builder = WordleTransformerModels(input_shape)
    transformer_reg_model = transformer_builder.build_transformer_regressor()
    transformer_reg_model, _ = train_model(transformer_reg_model, X_reg_train, y_reg_train)
    transformer_reg_model.save('transformer_regression_model.h5')
    print("âœ… Transformerå›å½’æ¨¡å‹å·²ä¿å­˜")

    # 4. æ¨¡å‹è¯„ä¼°
    print("\\n4. æ¨¡å‹è¯„ä¼°...")

    # è¯„ä¼°å›å½’æ¨¡å‹
    y_pred_lstm_reg, metrics_lstm_reg = evaluate_regression_model(lstm_reg_model, X_reg_test, y_reg_test, "åŸºç¡€LSTM")
    y_pred_bilstm_att_reg, metrics_bilstm_att_reg = evaluate_regression_model(bilstm_att_reg_model, X_reg_test,
                                                                              y_reg_test, "BiLSTM+Attention")
    y_pred_transformer_reg, metrics_transformer_reg = evaluate_regression_model(transformer_reg_model, X_reg_test,
                                                                                y_reg_test, "Transformer")

    # è¯„ä¼°åˆ†ç±»æ¨¡å‹
    y_pred_lstm_cls, y_pred_lstm_cls_prob, metrics_lstm_cls = evaluate_classification_model(lstm_cls_model, X_cls_test,
                                                                                            y_cls_test, "åŸºç¡€LSTM")

    # 5. ä¿å­˜ç‰¹å¾å·¥ç¨‹å¯¹è±¡ï¼ˆç”¨äºåç»­é¢„æµ‹ï¼‰
    import pickle
    with open('wordle_feature_engineering.pkl', 'wb') as f:
        pickle.dump(fe, f)
    print("\\nâœ… ç‰¹å¾å·¥ç¨‹å¯¹è±¡å·²ä¿å­˜ä¸º wordle_feature_engineering.pkl")

    # 6. ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š
    print("\\n5. ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š...")
    complete_comparison_data = {
        'æ¨¡å‹ç±»å‹': ['åŸºç¡€LSTMå›å½’', 'BiLSTM+Attentionå›å½’', 'Transformerå›å½’', 'åŸºç¡€LSTMåˆ†ç±»'],
        'ä»»åŠ¡ç±»å‹': ['å›å½’ï¼ˆå¹³å‡å°è¯•æ¬¡æ•°ï¼‰', 'å›å½’ï¼ˆå¹³å‡å°è¯•æ¬¡æ•°ï¼‰', 'å›å½’ï¼ˆå¹³å‡å°è¯•æ¬¡æ•°ï¼‰', 'åˆ†ç±»ï¼ˆé«˜æˆåŠŸç‡é¢„æµ‹ï¼‰'],
        'ä¸»è¦è¯„ä¼°æŒ‡æ ‡': ['RMSE', 'RMSE', 'RMSE', 'Accuracy'],
        'ä¸»è¦æŒ‡æ ‡å€¼': [f'{metrics_lstm_reg["rmse"]:.4f}',
                       f'{metrics_bilstm_att_reg["rmse"]:.4f}',
                       f'{metrics_transformer_reg["rmse"]:.4f}',
                       f'{metrics_lstm_cls["accuracy"]:.4f}'],
        'è¾…åŠ©æŒ‡æ ‡1': [f'MAE: {metrics_lstm_reg["mae"]:.4f}',
                      f'MAE: {metrics_bilstm_att_reg["mae"]:.4f}',
                      f'MAE: {metrics_transformer_reg["mae"]:.4f}',
                      f'F1: {metrics_lstm_cls["f1"]:.4f}'],
        'è¾…åŠ©æŒ‡æ ‡2': [f'MSE: {metrics_lstm_reg["mse"]:.4f}',
                      f'MSE: {metrics_bilstm_att_reg["mse"]:.4f}',
                      f'MSE: {metrics_transformer_reg["mse"]:.4f}',
                      f'Precision: {metrics_lstm_cls["precision"]:.4f}'],
        'æ¨¡å‹å¤æ‚åº¦': ['ä½', 'ä¸­', 'é«˜', 'ä½']
    }

    complete_comparison_df = pd.DataFrame(complete_comparison_data)
    complete_comparison_df.to_csv('complete_model_comparison_report.csv', index=False, encoding='utf-8')
    print("âœ… å®Œæ•´æ¨¡å‹å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜")

    print("\\n" + "=" * 60)
    print("Wordleç©å®¶è¡¨ç°é¢„æµ‹é¡¹ç›® - æ‰§è¡Œå®Œæˆ")
    print("=" * 60)

    # è¿”å›å…³é”®ç»“æœï¼ˆä¾›åç»­ä½¿ç”¨ï¼‰
    return {
        'data': df,
        'models': {
            'lstm_reg': lstm_reg_model,
            'lstm_cls': lstm_cls_model,
            'bilstm_att_reg': bilstm_att_reg_model,
            'transformer_reg': transformer_reg_model
        },
        'metrics': {
            'lstm_reg': metrics_lstm_reg,
            'lstm_cls': metrics_lstm_cls,
            'bilstm_att_reg': metrics_bilstm_att_reg,
            'transformer_reg': metrics_transformer_reg
        }
    }


# ==============================================================================
# 7. æ‰§è¡Œé¡¹ç›®ï¼ˆéœ€æŒ‡å®šæ•°æ®æ–‡ä»¶è·¯å¾„ï¼‰
# ==============================================================================
if __name__ == "__main__":
    # è¯·å°†æ­¤å¤„çš„æ–‡ä»¶è·¯å¾„æ›¿æ¢ä¸ºä½ çš„2023_MCM_Problem_C_Data.xlsxå®é™…è·¯å¾„
    DATA_FILE_PATH = "2023_MCM_Problem_C_Data.xlsx"

    # æ‰§è¡Œä¸»å‡½æ•°
    try:
        results = main(DATA_FILE_PATH, sequence_length=7)

        # æ‰“å°æœ€ç»ˆæ€§èƒ½æ€»ç»“
        print("\\nğŸ“‹ æœ€ç»ˆæ¨¡å‹æ€§èƒ½æ€»ç»“:")
        print(f"1. åŸºç¡€LSTMå›å½’æ¨¡å‹ - RMSE: {results['metrics']['lstm_reg']['rmse']:.4f}")
        print(f"2. BiLSTM+Attentionå›å½’æ¨¡å‹ - RMSE: {results['metrics']['bilstm_att_reg']['rmse']:.4f}")
        print(f"3. Transformerå›å½’æ¨¡å‹ - RMSE: {results['metrics']['transformer_reg']['rmse']:.4f}")
        print(f"4. åŸºç¡€LSTMåˆ†ç±»æ¨¡å‹ - Accuracy: {results['metrics']['lstm_cls']['accuracy']:.4f}")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ {DATA_FILE_PATH}")
        print("è¯·ç¡®ä¿2023_MCM_Problem_C_Data.xlsxæ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œæˆ–ä¿®æ”¹DATA_FILE_PATHä¸ºæ­£ç¡®è·¯å¾„")
    except Exception as e:
        print(f"âŒ é¡¹ç›®æ‰§è¡Œå‡ºé”™: {str(e)}")